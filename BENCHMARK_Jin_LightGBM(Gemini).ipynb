{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Water Quality Prediction: Benchmark Notebook (LightGBM Version)",
      "id": "55ac059e-684d-46a4-8dff-c3d2689fbd8f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Challenge Overview\nWelcome to the EY AI & Data Challenge 2026!...",
      "id": "23404dd1-c81f-40ee-a58e-7d10eb93cadd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Load In Dependencies",
      "id": "e79873ee-1295-451b-a2b9-6665a335d7bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "!pip install uv\n!uv pip install -r requirements.txt\n!pip install lightgbm",
      "id": "e68c8ebe-39b4-4295-a04d-d0aa2a4c75f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\nimport xarray as xr\nimport rioxarray as rxr\nimport rasterio\nfrom rasterio.windows import Window\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.spatial import cKDTree\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nfrom lightgbm import LGBMRegressor\n\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\nfrom pystac.extensions.eo import EOExtension as eo\nfrom datetime import date\nfrom tqdm import tqdm\nimport os",
      "id": "721ced6b-cf4c-4bd2-bfe4-78fc4175775c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Load Data",
      "id": "7cdca151-bf5a-4913-91f9-c49e534b6a2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "Water_Quality_df = pd.read_csv(\"water_quality_training_dataset.csv\")\nlandsat_train_features = pd.read_csv(\"landsat_features_training_200m.csv\")\nTerraclimate_df = pd.read_csv(\"terraclimate_features_training_full.csv\")\nurbanization_df = pd.read_csv(\"urbanization_train.csv\")\ncat_cols = [\"Total Alkalinity\", \"Electrical Conductance\", \"Dissolved Reactive Phosphorus\"]\nurbanization_df = urbanization_df.drop(columns=cat_cols, errors='ignore')",
      "id": "56c19c7a-692c-46ca-8f5c-840a41af4ae2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def combine_three_datasets(dataset1, dataset2, dataset3):\n    data = pd.concat([dataset1, dataset2, dataset3], axis=1)\n    data = data.loc[:, ~data.columns.duplicated()]\n    return data\n\nwq_data = combine_three_datasets(Water_Quality_df, landsat_train_features, Terraclimate_df)",
      "id": "1998f493-bc29-4605-a642-b59b80dd9f4f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Feature Engineering & Alignment (Train & Validation)",
      "id": "20853370-5c93-4ed6-ba66-68b1dd3aa243"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def classify_region(lat, lon):\n    try:\n        lat, lon = float(lat), float(lon)\n    except:\n        return \"Unknown\"\n    if lon < 20.5 and lat <= -32.0: return \"West_Coast\"\n    elif 20.5 <= lon <= 27.5 and -34.8 <= lat <= -32.0: return \"South_Coast\"\n    elif lon >= 29.0 and -31.0 <= lat <= -26.5: return \"East_Coast\"\n    elif 24.0 <= lon < 29.0 and -34.0 <= lat < -30.5: return \"Eastern_Cape\"\n    elif lat > -29.0: return \"Interior\"\n    else: return \"Northern_Arid\"\n\ndef get_season(month):\n    if month in [12, 1, 2]: return \"Summer\"\n    elif month in [3, 4, 5]: return \"Autumn\"\n    elif month in [6, 7, 8]: return \"Winter\"\n    else: return \"Spring\"\n\ndef preprocess_features(df, is_train=True, train_columns=None):\n    df_processed = df.copy()\n    df_processed['season'] = pd.to_datetime(df_processed['Sample Date'], dayfirst=True).dt.month.apply(get_season)\n    df_processed['region'] = df_processed.apply(lambda row: classify_region(row['Latitude'], row['Longitude']), axis=1)\n    df_processed['Region_Season'] = df_processed['region'] + '_' + df_processed['season']\n    df_processed = df_processed.drop(columns=['season', 'region'])\n    df_processed = pd.get_dummies(df_processed, columns=['Region_Season'], prefix='RS')\n    \n    cols_to_drop = ['Latitude', 'Longitude', 'Sample Date', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n    cols_to_drop_existing = [c for c in cols_to_drop if c in df_processed.columns]\n    X = df_processed.drop(columns=cols_to_drop_existing)\n    \n    if not is_train and train_columns is not None:\n        X = X.reindex(columns=train_columns, fill_value=0)\n        return X\n    return X, X.columns.tolist()",
      "id": "b8fea46e-d94c-4cb0-99bd-c933dbad24dd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Model Helper Functions (LightGBM)",
      "id": "48bcafdb-1fb1-4652-b345-26f70640d36d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def split_data(X, y, test_size=0.3, random_state=42):\n    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n\ndef scale_data(X_train, X_test):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled, scaler\n\ndef train_model(X_train_scaled, y_train):\n    model = LGBMRegressor(\n        n_estimators=300,\n        learning_rate=0.05,\n        max_depth=10,\n        num_leaves=31,\n        min_child_samples=6,\n        colsample_bytree=0.8,\n        random_state=42,\n        n_jobs=-1\n    )\n    model.fit(X_train_scaled, y_train)\n    return model\n\ndef evaluate_model(model, X_scaled, y_true, dataset_name=\"Test\"):\n    y_pred = model.predict(X_scaled)\n    r2 = r2_score(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    print(f\"\\n{dataset_name} Evaluation:\")\n    print(f\"R²: {r2:.3f}\")\n    print(f\"RMSE: {rmse:.3f}\")\n    return y_pred, r2, rmse",
      "id": "88bb47ea-675b-45bd-8498-41083cd099b2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def run_pipeline(X, y, param_name=\"Parameter\"):\n    print(f\"\\n{'='*60}\")\n    print(f\"Training Model for {param_name}\")\n    print(f\"{'='*60}\")\n    \n    X_train, X_test, y_train, y_test = split_data(X, y)\n    X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n    model = train_model(X_train_scaled, y_train)\n    \n    y_train_pred, r2_train, rmse_train = evaluate_model(model, X_train_scaled, y_train, \"Train\")\n    y_test_pred, r2_test, rmse_test = evaluate_model(model, X_test_scaled, y_test, \"Test\")\n\n    feat_imp = pd.Series(model.feature_importances_, index=X.columns)\n    top25 = feat_imp.nlargest(25).sort_values()\n\n    fig, ax = plt.subplots(figsize=(9, 7))\n    bars = ax.barh(top25.index, top25.values, color=\"steelblue\", edgecolor=\"white\")\n    for bar, val in zip(bars, top25.values):\n        ax.text(val + 0.001, bar.get_y() + bar.get_height() / 2, f\"{val:.4f}\", va=\"center\", ha=\"left\", fontsize=8)\n    ax.set_xlabel(\"Feature Importance\")\n    ax.set_title(f\"Top 25 Feature Importances — {param_name}\")\n    plt.tight_layout()\n    plt.show()\n\n    results = {\"Parameter\": param_name, \"R2_Train\": r2_train, \"RMSE_Train\": rmse_train, \"R2_Test\": r2_test, \"RMSE_Test\": rmse_test}\n    return model, scaler, pd.DataFrame([results]), feat_imp.nlargest(25)",
      "id": "487fdd81-136d-47d7-a08f-9f601fac0abf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Train the Models",
      "id": "613a0c65-4319-4a88-849a-615fcc4f8143"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "wq_data = wq_data.fillna(wq_data.median(numeric_only=True))\n\ny_TA  = wq_data['Total Alkalinity']\ny_EC  = wq_data['Electrical Conductance']\ny_DRP = wq_data['Dissolved Reactive Phosphorus']\n\nX, train_feature_cols = preprocess_features(wq_data, is_train=True)\n\nmodel_TA,  scaler_TA,  results_TA,  top25_TA  = run_pipeline(X, y_TA,  \"Total Alkalinity\")\nmodel_EC,  scaler_EC,  results_EC,  top25_EC  = run_pipeline(X, y_EC,  \"Electrical Conductance\")\nmodel_DRP, scaler_DRP, results_DRP, top25_DRP = run_pipeline(X, y_DRP, \"Dissolved Reactive Phosphorus\")",
      "id": "6385b7df-a4df-47a7-85db-b0751de53e01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "results_summary = pd.concat([results_TA, results_EC, results_DRP], ignore_index=True)\ndisplay(results_summary)",
      "id": "a443f8ee-a76f-4528-98d5-bd96f29dbad6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Validation & Submission",
      "id": "5104b585-f5e4-4d8e-a80a-b56990fbe574"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "test_file = pd.read_csv(\"submission_template.csv\")\nlandsat_val_features = pd.read_csv(\"landsat_features_validation_200m.csv\")\nTerraclimate_val_df = pd.read_csv(\"terraclimate_features_validation_full.csv\")\nurbanization_val_df = pd.read_csv(\"urbanization_val.csv\")\nurbanization_val_df = urbanization_val_df.drop(columns=cat_cols, errors='ignore')\n\nval_data = combine_three_datasets(test_file, landsat_val_features, Terraclimate_val_df)\nval_data = val_data.fillna(val_data.median(numeric_only=True))\n\n# Use the unified preprocess function, aligning validation columns to the training columns\nsubmission_val_data = preprocess_features(val_data, is_train=False, train_columns=train_feature_cols)\ndisplay(submission_val_data.head())",
      "id": "171606ea-b91f-4f27-a4c7-16a0d80a777e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "X_sub_scaled_TA = scaler_TA.transform(submission_val_data)\npred_TA_submission = model_TA.predict(X_sub_scaled_TA)\n\nX_sub_scaled_EC = scaler_EC.transform(submission_val_data)\npred_EC_submission = model_EC.predict(X_sub_scaled_EC)\n\nX_sub_scaled_DRP = scaler_DRP.transform(submission_val_data)\npred_DRP_submission = model_DRP.predict(X_sub_scaled_DRP)",
      "id": "5142163a-aec2-4abc-bd25-ad06f2af5089"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "submission_df = pd.DataFrame({\n    'Latitude': test_file['Latitude'].values,\n    'Longitude': test_file['Longitude'].values,\n    'Sample Date': test_file['Sample Date'].values,\n    'Total Alkalinity': pred_TA_submission,\n    'Electrical Conductance': pred_EC_submission,\n    'Dissolved Reactive Phosphorus': pred_DRP_submission\n})\ndisplay(submission_df.head())",
      "id": "2906cad2-2dbd-47d4-a2b3-2eb77dead357"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "submission_df.to_csv(\"/tmp/submission_v10.csv\", index=False)\nsession.sql(\"\"\"\n    PUT file:///tmp/submission_v10.csv\n    'snow://workspace/USER$.PUBLIC.\"EY-AI-and-Data-Challenge\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")",
      "id": "55731ddb-db33-4236-b344-3dad16c36f6f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}