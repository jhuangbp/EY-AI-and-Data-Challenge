{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Water Quality Prediction: Benchmark Notebook (CatBoost Version)",
      "id": "c83e43f1-2746-4038-a492-5d8c3d51f756"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Challenge Overview\nWelcome to the EY AI & Data Challenge 2026!...",
      "id": "7a187f50-b104-4da7-bf2e-4828a2c759ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Load In Dependencies",
      "id": "8cec61a8-0d66-4a36-9ba7-6c7735e42cc9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "!pip install uv\n!uv pip install -r requirements.txt\n!pip install catboost",
      "id": "6a742f72-9757-464a-9b3b-ba43dbe91195"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\nimport xarray as xr\nimport rioxarray as rxr\nimport rasterio\nfrom rasterio.windows import Window\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.spatial import cKDTree\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nfrom catboost import CatBoostRegressor\n\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\nfrom pystac.extensions.eo import EOExtension as eo\nfrom datetime import date\nfrom tqdm import tqdm\nimport os",
      "id": "4ccca0a2-9651-4dd1-b719-95658909e991"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Load Data",
      "id": "8f37f5f9-370c-493e-8071-33b2ab43a19f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "Water_Quality_df = pd.read_csv(\"water_quality_training_dataset.csv\")\nlandsat_train_features = pd.read_csv(\"landsat_features_training_200m.csv\")\nTerraclimate_df = pd.read_csv(\"terraclimate_features_training_full.csv\")\nurbanization_df = pd.read_csv(\"urbanization_train.csv\")\ncat_cols = [\"Total Alkalinity\", \"Electrical Conductance\", \"Dissolved Reactive Phosphorus\"]\nurbanization_df = urbanization_df.drop(columns=cat_cols, errors='ignore')",
      "id": "a49189b0-f100-48b7-a34b-1e290960242f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def combine_three_datasets(dataset1, dataset2, dataset3):\n    data = pd.concat([dataset1, dataset2, dataset3], axis=1)\n    data = data.loc[:, ~data.columns.duplicated()]\n    return data\n\nwq_data = combine_three_datasets(Water_Quality_df, landsat_train_features, Terraclimate_df)",
      "id": "99e5527d-bd27-4801-98cb-2104a14da7ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Feature Engineering & Alignment (Train & Validation)",
      "id": "26cbeda8-0dee-4ea2-9367-e02824483f88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def classify_region(lat, lon):\n    try:\n        lat, lon = float(lat), float(lon)\n    except:\n        return \"Unknown\"\n    if lon < 20.5 and lat <= -32.0: return \"West_Coast\"\n    elif 20.5 <= lon <= 27.5 and -34.8 <= lat <= -32.0: return \"South_Coast\"\n    elif lon >= 29.0 and -31.0 <= lat <= -26.5: return \"East_Coast\"\n    elif 24.0 <= lon < 29.0 and -34.0 <= lat < -30.5: return \"Eastern_Cape\"\n    elif lat > -29.0: return \"Interior\"\n    else: return \"Northern_Arid\"\n\ndef get_season(month):\n    if month in [12, 1, 2]: return \"Summer\"\n    elif month in [3, 4, 5]: return \"Autumn\"\n    elif month in [6, 7, 8]: return \"Winter\"\n    else: return \"Spring\"\n\ndef preprocess_features(df, is_train=True, train_columns=None):\n    df_processed = df.copy()\n    df_processed['season'] = pd.to_datetime(df_processed['Sample Date'], dayfirst=True).dt.month.apply(get_season)\n    df_processed['region'] = df_processed.apply(lambda row: classify_region(row['Latitude'], row['Longitude']), axis=1)\n    df_processed['Region_Season'] = df_processed['region'] + '_' + df_processed['season']\n    df_processed = df_processed.drop(columns=['season', 'region'])\n    df_processed = pd.get_dummies(df_processed, columns=['Region_Season'], prefix='RS')\n    \n    cols_to_drop = ['Latitude', 'Longitude', 'Sample Date', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n    cols_to_drop_existing = [c for c in cols_to_drop if c in df_processed.columns]\n    X = df_processed.drop(columns=cols_to_drop_existing)\n    \n    if not is_train and train_columns is not None:\n        X = X.reindex(columns=train_columns, fill_value=0)\n        return X\n    return X, X.columns.tolist()",
      "id": "2e226c3d-a96a-4df6-8cff-cff16ce02986"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Model Helper Functions (CatBoost)",
      "id": "89cdfb92-a676-4ac2-a4a5-c0f42bd5b71c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def split_data(X, y, test_size=0.3, random_state=42):\n    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n\ndef scale_data(X_train, X_test):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled, scaler\n\ndef train_model(X_train_scaled, y_train):\n    model = CatBoostRegressor(\n        iterations=500,          # 迭代次數 (類似 n_estimators)\n        learning_rate=0.05,      # 學習率\n        depth=6,                 # 樹的深度，CatBoost 通常設 6 就很強\n        l2_leaf_reg=3,           # L2 正則化參數，防止過擬合\n        loss_function='RMSE',    # 損失函數\n        random_seed=42,\n        verbose=False            # 設為 False 避免訓練時印出一大堆進度條\n    )\n    model.fit(X_train_scaled, y_train)\n    return model\n\ndef evaluate_model(model, X_scaled, y_true, dataset_name=\"Test\"):\n    y_pred = model.predict(X_scaled)\n    r2 = r2_score(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    print(f\"\\n{dataset_name} Evaluation:\")\n    print(f\"R²: {r2:.3f}\")\n    print(f\"RMSE: {rmse:.3f}\")\n    return y_pred, r2, rmse",
      "id": "b321f700-84ba-4563-89b1-d920ce7ed473"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "def run_pipeline(X, y, param_name=\"Parameter\"):\n    print(f\"\\n{'='*60}\")\n    print(f\"Training Model for {param_name}\")\n    print(f\"{'='*60}\")\n    \n    X_train, X_test, y_train, y_test = split_data(X, y)\n    X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n    model = train_model(X_train_scaled, y_train)\n    \n    y_train_pred, r2_train, rmse_train = evaluate_model(model, X_train_scaled, y_train, \"Train\")\n    y_test_pred, r2_test, rmse_test = evaluate_model(model, X_test_scaled, y_test, \"Test\")\n\n    feat_imp = pd.Series(model.feature_importances_, index=X.columns)\n    top25 = feat_imp.nlargest(25).sort_values()\n\n    fig, ax = plt.subplots(figsize=(9, 7))\n    bars = ax.barh(top25.index, top25.values, color=\"steelblue\", edgecolor=\"white\")\n    for bar, val in zip(bars, top25.values):\n        ax.text(val + 0.001, bar.get_y() + bar.get_height() / 2, f\"{val:.4f}\", va=\"center\", ha=\"left\", fontsize=8)\n    ax.set_xlabel(\"Feature Importance\")\n    ax.set_title(f\"Top 25 Feature Importances — {param_name}\")\n    plt.tight_layout()\n    plt.show()\n\n    results = {\"Parameter\": param_name, \"R2_Train\": r2_train, \"RMSE_Train\": rmse_train, \"R2_Test\": r2_test, \"RMSE_Test\": rmse_test}\n    return model, scaler, pd.DataFrame([results]), feat_imp.nlargest(25)",
      "id": "4262c651-c648-480f-a272-510aa65511ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Train the Models",
      "id": "601c5824-f3a7-4873-98e7-24b253c9bf13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "wq_data = wq_data.fillna(wq_data.median(numeric_only=True))\n\ny_TA  = wq_data['Total Alkalinity']\ny_EC  = wq_data['Electrical Conductance']\ny_DRP = wq_data['Dissolved Reactive Phosphorus']\n\nX, train_feature_cols = preprocess_features(wq_data, is_train=True)\n\nmodel_TA,  scaler_TA,  results_TA,  top25_TA  = run_pipeline(X, y_TA,  \"Total Alkalinity\")\nmodel_EC,  scaler_EC,  results_EC,  top25_EC  = run_pipeline(X, y_EC,  \"Electrical Conductance\")\nmodel_DRP, scaler_DRP, results_DRP, top25_DRP = run_pipeline(X, y_DRP, \"Dissolved Reactive Phosphorus\")",
      "id": "090b620c-bc28-441c-8c86-ff081bb52cd4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "results_summary = pd.concat([results_TA, results_EC, results_DRP], ignore_index=True)\ndisplay(results_summary)",
      "id": "d4353d94-5f6f-4d6e-8ebf-916d8523ede9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Validation & Submission",
      "id": "a690c2f4-9db1-4772-a6f0-c5db67ce8651"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "test_file = pd.read_csv(\"submission_template.csv\")\nlandsat_val_features = pd.read_csv(\"landsat_features_validation_200m.csv\")\nTerraclimate_val_df = pd.read_csv(\"terraclimate_features_validation_full.csv\")\nurbanization_val_df = pd.read_csv(\"urbanization_val.csv\")\nurbanization_val_df = urbanization_val_df.drop(columns=cat_cols, errors='ignore')\n\nval_data = combine_three_datasets(test_file, landsat_val_features, Terraclimate_val_df)\nval_data = val_data.fillna(val_data.median(numeric_only=True))\n\n# Use the unified preprocess function, aligning validation columns to the training columns\nsubmission_val_data = preprocess_features(val_data, is_train=False, train_columns=train_feature_cols)\ndisplay(submission_val_data.head())",
      "id": "c883a14d-e5da-4935-b1ac-17a7b0b9f279"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "X_sub_scaled_TA = scaler_TA.transform(submission_val_data)\npred_TA_submission = model_TA.predict(X_sub_scaled_TA)\n\nX_sub_scaled_EC = scaler_EC.transform(submission_val_data)\npred_EC_submission = model_EC.predict(X_sub_scaled_EC)\n\nX_sub_scaled_DRP = scaler_DRP.transform(submission_val_data)\npred_DRP_submission = model_DRP.predict(X_sub_scaled_DRP)",
      "id": "23a393b2-44b3-4756-a5ba-139ea55eb4a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "submission_df = pd.DataFrame({\n    'Latitude': test_file['Latitude'].values,\n    'Longitude': test_file['Longitude'].values,\n    'Sample Date': test_file['Sample Date'].values,\n    'Total Alkalinity': pred_TA_submission,\n    'Electrical Conductance': pred_EC_submission,\n    'Dissolved Reactive Phosphorus': pred_DRP_submission\n})\ndisplay(submission_df.head())",
      "id": "21c574d7-e444-45c2-8c8b-5297a1f1b786"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "submission_df.to_csv(\"/tmp/submission_v10.csv\", index=False)\nsession.sql(\"\"\"\n    PUT file:///tmp/submission_v10.csv\n    'snow://workspace/USER$.PUBLIC.\"EY-AI-and-Data-Challenge\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")",
      "id": "a04a36a9-fcc1-4f30-81f8-9ec61e3e9a32"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}