{
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport requests\nimport math\nfrom math import sqrt\n\n# -----------------------------\n# 0) Utilities\n# -----------------------------\ndef haversine(lat1, lon1, lat2, lon2):\n    \"\"\"\n    lat1, lon1: scalar\n    lat2, lon2: numpy arrays\n    return: numpy array distances (km)\n    \"\"\"\n    R = 6371.0\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    return R * c\n\ndef is_wgs84_like(lat_series, lon_series):\n    lat_ok = lat_series.between(-90, 90).mean()\n    lon_ok = lon_series.between(-180, 180).mean()\n    return (lat_ok > 0.99) and (lon_ok > 0.99)\n\ndef get_elevations_batched(locations, batch_size=100):\n    \"\"\"\n    Open-Elevation 批次查詢；避免一次塞太多 locations 造成失敗。\n    locations: list of (lat, lon)\n    \"\"\"\n    out = []\n    for i in range(0, len(locations), batch_size):\n        chunk = locations[i:i + batch_size]\n        loc_str = \"|\".join([f\"{lat},{lon}\" for lat, lon in chunk])\n        url = f\"https://api.open-elevation.com/api/v1/lookup?locations={loc_str}\"\n        try:\n            resp = requests.get(url, timeout=20)\n            if resp.status_code == 200:\n                data = resp.json()\n                if \"results\" in data and len(data[\"results\"]) == len(chunk):\n                    out.extend([r.get(\"elevation\", np.nan) for r in data[\"results\"]])\n                else:\n                    out.extend([np.nan] * len(chunk))\n            else:\n                out.extend([np.nan] * len(chunk))\n        except Exception as e:\n            print(f\"API error: {e}\")\n            out.extend([np.nan] * len(chunk))\n    return out\n\ndef get_season(date_str):\n    # 南半球: 1=夏季 Dec-Feb, 2=秋季 Mar-May, 3=冬季 Jun-Aug, 4=春季 Sep-Nov\n    try:\n        month = pd.to_datetime(date_str, format=\"%d-%m-%Y\").month\n        if month in [12, 1, 2]: return 1\n        elif month in [3, 4, 5]: return 2\n        elif month in [6, 7, 8]: return 3\n        else: return 4\n    except:\n        return np.nan\n\n# -----------------------------\n# 1) Core Pipeline\n# -----------------------------\ndef build_features(\n    water_df: pd.DataFrame,\n    dams_df: pd.DataFrame,\n    radii_km=(5, 10, 25),\n    in_dam_km=5.0,\n    use_elevation=True,\n    elevation_batch_size=100,\n):\n    \"\"\"\n    將 water_df 加上 dam-based features。\n    所有 feature 均為「相對量」或「周邊統計摘要」，不暴露特定 dam 的 ID 或絕對位置。\n    \"\"\"\n\n    # ---- copy to avoid in-place side effects\n    water_df = water_df.copy()\n    dams_df  = dams_df.copy()\n\n    # ---- rename columns to standard\n    if \"Y_COORD\" in dams_df.columns:\n        dams_df = dams_df.rename(columns={\"Y_COORD\": \"dam_lat\", \"X_COORD\": \"dam_lon\"})\n    if \"Latitude\" in water_df.columns:\n        water_df = water_df.rename(columns={\"Latitude\": \"sample_lat\", \"Longitude\": \"sample_lon\"})\n\n    # ---- sanity check\n    if not is_wgs84_like(dams_df[\"dam_lat\"], dams_df[\"dam_lon\"]):\n        print(\"WARNING: dam_lat/dam_lon 看起來不像 WGS84 經緯度\")\n    if not is_wgs84_like(water_df[\"sample_lat\"], water_df[\"sample_lon\"]):\n        print(\"WARNING: sample_lat/sample_lon 看起來不像 WGS84 經緯度\")\n\n    # ---- precompute dam arrays\n    dam_lats = dams_df[\"dam_lat\"].to_numpy()\n    dam_lons = dams_df[\"dam_lon\"].to_numpy()\n\n    has_area    = \"Shape_Area\"   in dams_df.columns\n    has_length  = \"Shape_Length\" in dams_df.columns\n    has_area_km = \"AREA_KM2\"     in dams_df.columns\n\n    dam_shape_area   = dams_df[\"Shape_Area\"].to_numpy()   if has_area    else np.zeros(len(dams_df))\n    dam_shape_length = dams_df[\"Shape_Length\"].to_numpy() if has_length  else np.zeros(len(dams_df))\n    dam_area_km2     = dams_df[\"AREA_KM2\"].to_numpy()     if has_area_km else np.zeros(len(dams_df))\n\n    # pre-compute per-dam geometry ratios (shape-level, not location-level)\n    eps = 1e-12\n    dam_apr   = dam_shape_area / (dam_shape_length + eps)                         # area/perimeter ratio\n    dam_comp  = (4.0 * math.pi * dam_shape_area) / ((dam_shape_length + eps)**2)  # compactness\n\n    # ---- per-sample feature accumulators\n    dist_nearest    = []\n    within_counts   = {r: [] for r in radii_km}\n    within_area_sum = {r: [] for r in radii_km}\n    within_area_mean= {r: [] for r in radii_km}\n    within_area_max = {r: [] for r in radii_km}\n    within_apr_mean = {r: [] for r in radii_km}   # mean area/perimeter ratio\n    within_comp_mean= {r: [] for r in radii_km}   # mean compactness\n    within_dist_mean= {r: [] for r in radii_km}   # mean distance to dams inside radius\n    nearest_apr     = []\n    nearest_comp    = []\n    nearest_area_km = []\n    nearest_area_norm = []   # nearest dam area / mean area of all dams in same radius band\n\n    global_mean_area = np.nanmean(dam_shape_area) if has_area else np.nan\n\n    # elevation list for sample points (filled if use_elevation)\n    sample_elev_list = [np.nan] * len(water_df)\n    # we also need nearest-dam elevations for relative elevation feature\n    nearest_dam_lat_list = []\n    nearest_dam_lon_list = []\n\n    for i, (_, row) in enumerate(water_df.iterrows()):\n        dists = haversine(row[\"sample_lat\"], row[\"sample_lon\"], dam_lats, dam_lons)\n        idx   = int(np.argmin(dists))\n\n        dist_nearest.append(float(dists[idx]))\n        nearest_dam_lat_list.append(float(dam_lats[idx]))\n        nearest_dam_lon_list.append(float(dam_lons[idx]))\n\n        # nearest dam geometry (shape descriptors, not raw area/coords)\n        nearest_apr.append(float(dam_apr[idx]))\n        nearest_comp.append(float(dam_comp[idx]))\n        nearest_area_km.append(float(dam_area_km2[idx]) if has_area_km else np.nan)\n\n        for r in radii_km:\n            mask = dists <= r\n            n    = int(mask.sum())\n            within_counts[r].append(n)\n\n            areas_r  = dam_shape_area[mask]\n            dists_r  = dists[mask]\n            apr_r    = dam_apr[mask]\n            comp_r   = dam_comp[mask]\n\n            within_area_sum[r].append(float(areas_r.sum())  if n > 0 else 0.0)\n            within_area_mean[r].append(float(areas_r.mean()) if n > 0 else np.nan)\n            within_area_max[r].append(float(areas_r.max())  if n > 0 else np.nan)\n            within_apr_mean[r].append(float(apr_r.mean())   if n > 0 else np.nan)\n            within_comp_mean[r].append(float(comp_r.mean()) if n > 0 else np.nan)\n            within_dist_mean[r].append(float(dists_r.mean()) if n > 0 else np.nan)\n\n        # nearest dam area normalised by global mean (removes absolute scale)\n        nearest_area_norm.append(\n            float(dam_shape_area[idx] / global_mean_area)\n            if (has_area and global_mean_area > 0) else np.nan\n        )\n\n    # ---- store non-location features\n    water_df[\"distance_to_nearest_dam_km\"] = dist_nearest\n\n    # log-distance is more generalizable than raw distance\n    water_df[\"log1p_distance_to_nearest_dam\"] = np.log1p(water_df[\"distance_to_nearest_dam_km\"])\n\n    # is sample point \"inside\" nearest dam footprint?\n    water_df[\"is_in_dam_zone\"] = (water_df[\"distance_to_nearest_dam_km\"] < in_dam_km).astype(int)\n\n    # nearest dam shape descriptors\n    water_df[\"nearest_dam_area_perimeter_ratio\"] = nearest_apr\n    water_df[\"nearest_dam_compactness\"]           = nearest_comp\n    water_df[\"nearest_dam_area_km2\"]              = nearest_area_km\n    water_df[\"nearest_dam_area_norm\"]             = nearest_area_norm  # relative to global mean\n\n    # per-radius aggregated features\n    for r in radii_km:\n        water_df[f\"dam_count_within_{r}km\"]          = within_counts[r]\n        water_df[f\"dam_area_sum_within_{r}km\"]        = within_area_sum[r]\n        water_df[f\"dam_area_mean_within_{r}km\"]       = within_area_mean[r]\n        water_df[f\"dam_area_max_within_{r}km\"]        = within_area_max[r]\n        water_df[f\"dam_apr_mean_within_{r}km\"]        = within_apr_mean[r]\n        water_df[f\"dam_compactness_mean_within_{r}km\"]= within_comp_mean[r]\n        water_df[f\"dam_dist_mean_within_{r}km\"]       = within_dist_mean[r]\n\n    # dam density proxies (count / area of search circle)\n    for r in radii_km:\n        circle_area = math.pi * r**2  # km²\n        water_df[f\"dam_density_{r}km\"] = water_df[f\"dam_count_within_{r}km\"] / circle_area\n\n    # multi-scale dam pressure: weighted sum of counts by inverse-radius\n    if len(radii_km) >= 2:\n        water_df[\"dam_pressure_score\"] = sum(\n            water_df[f\"dam_count_within_{r}km\"] / r for r in radii_km\n        )\n\n    # ---- elevation features (relative only — no absolute values retained)\n    if use_elevation:\n        sample_locations = list(zip(water_df[\"sample_lat\"], water_df[\"sample_lon\"]))\n        dam_locations    = list(zip(nearest_dam_lat_list, nearest_dam_lon_list))\n\n        all_locations = sample_locations + dam_locations\n        all_elev      = get_elevations_batched(all_locations, batch_size=elevation_batch_size)\n\n        sample_elevs = np.array(all_elev[:len(sample_locations)], dtype=float)\n        nearest_dam_elevs = np.array(all_elev[len(sample_locations):], dtype=float)\n\n        # RELATIVE elevation: how much higher/lower is sample vs nearest dam\n        elev_diff = sample_elevs - nearest_dam_elevs\n        water_df[\"elev_diff_sample_minus_dam\"] = elev_diff  # positive => upstream, negative => downstream\n\n        # categorical position (still useful as a feature, but derived from relative not absolute elevation)\n        def _pos(diff, dist, in_dam_km):\n            if np.isnan(diff): return \"unknown\"\n            if dist < in_dam_km: return \"in_dam\"\n            if diff > 0:  return \"upstream\"\n            if diff < 0:  return \"downstream\"\n            return \"in_dam\"\n\n        water_df[\"position_relative_to_dam\"] = [\n            _pos(d, dist, in_dam_km)\n            for d, dist in zip(elev_diff, dist_nearest)\n        ]\n    else:\n        water_df[\"elev_diff_sample_minus_dam\"]  = np.nan\n        water_df[\"position_relative_to_dam\"]    = \"unknown\"\n\n    # ---- season + evap proxy (time-based, not location-based)\n    if \"Sample Date\" in water_df.columns:\n        water_df[\"season\"] = water_df[\"Sample Date\"].apply(get_season)\n    else:\n        water_df[\"season\"] = np.nan\n\n    # evap proxy uses nearest dam area (already captured above) × season factor\n    water_df[\"evap_proxy\"] = (\n        water_df[\"nearest_dam_area_km2\"]\n        * water_df[\"season\"].apply(lambda s: 1.5 if s == 1 else 1.0)\n    )\n\n    # ---- ALWAYS drop raw coordinates and any ID/name columns\n    cols_to_drop = [\n        \"sample_lat\", \"sample_lon\",   # raw location — drop to prevent leakage\n        \"nearest_dam_id\",              # identity of dam leaks location\n        \"dam_lat\", \"dam_lon\",\n        \"NAME\", \"STATION\", \"ALIAS\", \"TYPE\",\n        \"OBJECTID\", \"FEAT_ID\", \"NEAREST_DAM_ID\",\n        \"DAMS500G_\", \"DAMS500G_I\",\n        \"has_station_code\", \"has_alias\",\n        # raw single-dam geometry (replaced by shape-descriptor + normalised versions)\n        \"Shape_Area\", \"Shape_Length\", \"AREA\", \"PERIMETER\", \"AREA_KM2\",\n        # absolute elevation values\n        \"sample_elevation\", \"dam_elevation\",\n    ]\n    water_df = water_df.drop(columns=cols_to_drop, errors=\"ignore\")\n\n    return water_df\n\n# -----------------------------\n# 2) Runner: apply to train & valid separately\n# -----------------------------\ndef run_pipeline_for_two_sets(\n    dams_path,\n    train_path,\n    valid_path,\n    out_train_path=\"enhanced_train.csv\",\n    out_valid_path=\"enhanced_valid.csv\",\n    use_elevation=True\n):\n    dams_df  = pd.read_csv(dams_path)\n    train_df = pd.read_csv(train_path)\n    valid_df = pd.read_csv(valid_path)\n\n    train_enh = build_features(train_df, dams_df, use_elevation=use_elevation)\n    valid_enh = build_features(valid_df, dams_df, use_elevation=use_elevation)\n\n    train_enh.to_csv(out_train_path, index=False)\n    valid_enh.to_csv(out_valid_path, index=False)\n\n    print(\"Train enhanced shape:\", train_enh.shape)\n    print(\"Valid enhanced shape:\",  valid_enh.shape)\n    print(\"\\nNew dam-related columns:\")\n    dam_cols = [c for c in train_enh.columns if any(\n        kw in c for kw in [\"dam\", \"elev\", \"position\", \"evap\", \"season\", \"compactness\", \"density\", \"pressure\"]\n    )]\n    for c in dam_cols:\n        print(\" \", c)\n\n    return train_enh, valid_enh\n\n# -----------------------------\n# 3) Example usage\n# -----------------------------\nif __name__ == \"__main__\":\n    dams_path  = \"Dams_dataset.csv\"\n    train_path = \"water_quality_training_dataset.csv\"\n    valid_path = \"submission_template.csv\"\n\n    train_enh, valid_enh = run_pipeline_for_two_sets(\n        dams_path=dams_path,\n        train_path=train_path,\n        valid_path=valid_path,\n        out_train_path=\"dams_training_dataset.csv\",\n        out_valid_path=\"dams_validation_dataset.csv\",\n        use_elevation=True  # set False to skip Open-Elevation API calls\n    )\n",
      "metadata": {
        "id": "T3Jq9yop7dqc",
        "language": "python"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4830c74f-db00-45d9-b5fa-3c64bcfd5d1f"
    },
    {
      "cell_type": "markdown",
      "source": "## 修改說明：如何降低位置洩漏\n\n### 原版問題\n| 原始欄位 | 洩漏原因 |\n|---|---|\n| `nearest_dam_id` | 直接 encode 哪個 dam，等於暴露位置 |\n| `NAME`, `STATION`, `ALIAS` | 特定 dam 識別符 |\n| `TYPE` | 結合距離可反推位置 |\n| `AREA`, `Shape_Area`, `Shape_Length` (raw) | 某一特定 dam 的值，模型可記憶 |\n| `sample_lat`, `sample_lon` | 直接暴露位置 |\n| `sample_elevation`, `dam_elevation` (絕對值) | 絕對海拔含地理資訊 |\n\n### 修改策略\n1. **移除所有 ID 和識別欄位**：`nearest_dam_id`, `NAME`, `STATION`, `ALIAS`, `OBJECTID` 等全部 drop。\n2. **以相對量取代絕對量**：絕對海拔 → `elev_diff_sample_minus_dam`（相對高差），模型學到的是「sample 比 dam 高多少」而非「在哪裡」。\n3. **以形狀描述子取代原始幾何數值**：raw `Shape_Area` / `Shape_Length` → `compactness`、`area_perimeter_ratio`，加上 `nearest_dam_area_norm`（相對全域均值的比例），模型看到的是「這個 dam 的形狀特性」而非「某個特定 dam 的尺寸」。\n4. **以多半徑統計摘要取代單點查找**：`dam_count`, `dam_area_mean`, `dam_area_max`, `dam_apr_mean`, `dam_compactness_mean`, `dam_dist_mean` 等都是「周邊 dam 群的統計」，不指向任何特定 dam。\n5. **dam density 和 dam pressure**：新增密度（count/面積）和加權壓力分數，是 positional-agnostic 的環境指標。\n6. **drop 原始座標**：`sample_lat`, `sample_lon` 也一併 drop，避免模型透過座標直接記憶訓練點。\n",
      "metadata": {
        "id": "066davyn7LqU",
        "codeCollapsed": true
      },
      "id": "2c919aae-a103-44d9-9b77-e2cce7004e43"
    }
  ],
  "metadata": {
    "colab": {
      "name": "Dams_features_generalized",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}