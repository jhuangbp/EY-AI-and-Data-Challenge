{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9537d42a-42be-4f34-8d56-3915a90952e1",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "!pip install uv\n!uv pip install  -r requirements.txt ",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ce22b326-fa37-4371-9056-29b3488e63f5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\n\n# Multi-dimensional arrays and datasets (e.g., NetCDF, Zarr)\nimport xarray as xr\n\n# Geospatial raster data handling with CRS support\nimport rioxarray as rxr\n\n# Raster operations and spatial windowing\nimport rasterio\nfrom rasterio.windows import Window\n\n# Feature preprocessing and data splitting\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.spatial import cKDTree\n\n# Machine Learning\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\n# Planetary Computer tools for STAC API access and authentication\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\nfrom pystac.extensions.eo import EOExtension as eo\n\nfrom datetime import date\nfrom tqdm import tqdm\nimport os \nfrom xgboost import XGBRegressor",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dc8a69ab-aa97-4aff-b803-85eb73031e2f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "!pip install geopandas",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0176bae8-049d-4191-82ab-de2f55c03769",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nimport numpy as np",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "33c5b704-41ef-48b3-aac8-d268b6b40393",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Load Rivers and Dams data"
    },
    {
      "cell_type": "code",
      "id": "a671d2a7-7188-4d96-ab3f-a3aa3b43d39d",
      "metadata": {
        "language": "python"
      },
      "source": "import geopandas as gpd\nrivers = gpd.read_file(\"Rivers_Data/Rivers.shp\")\nrivers.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1b51c37d-802e-4741-98cb-ab207fb3ce96",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "rivers.crs",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "faf57f66-7d80-4dea-8bfd-5ca671857938",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Load the data we want to join"
    },
    {
      "id": "7a594031-4757-464b-8858-712478d987cf",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "water_training_df = pd.read_csv(\"water_quality_training_dataset.csv\")\nwater_training_df.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2971d004-96b4-49b5-b061-d323694de8ea",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "water_validation_df = pd.read_csv(\"submission_template.csv\")\nwater_validation_df",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f179cb0c-9cad-49ae-9f98-b82d3712f090",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "water_training_df.columns",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "630adab1-8874-46ee-a5a4-71e92918e220",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# define longtitude and latitude column names\nlon_col = \"Longitude\"\nlat_col = \"Latitude\"\n\nwater_training_gdf = gpd.GeoDataFrame(\n    water_training_df,\n    geometry=gpd.points_from_xy(water_training_df[lon_col], water_training_df[lat_col]),\n    crs=\"EPSG:4326\"  # Longtitude and latitude\n)\n\nprint(water_training_gdf.crs)\nwater_training_gdf.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3b65613f-22be-4289-9d79-3a96c98416c5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# define longtitude and latitude column names\nlon_col = \"Longitude\"\nlat_col = \"Latitude\"\n\nwater_validation_gdf = gpd.GeoDataFrame(\n    water_validation_df,\n    geometry=gpd.points_from_xy(water_validation_df[lon_col], water_validation_df[lat_col]),\n    crs=\"EPSG:4326\"  # Longtitude and latitude\n)\n\nprint(water_validation_gdf.crs)\nwater_validation_gdf.head()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "67ddd10c-7309-4790-8556-00fe24ef1584",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Check for the training set\nprint(water_training_gdf[[lon_col, lat_col]].describe())\nprint(water_training_gdf[[lon_col, lat_col]].isna().sum())",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "448d3f98-5fa7-4ab1-819c-8be0196fdcf4",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Check for the validation set\nprint(water_validation_gdf[[lon_col, lat_col]].describe())\nprint(water_validation_gdf[[lon_col, lat_col]].isna().sum())\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5f762ed9-16af-470d-a5d7-0ca72d22d33f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Project to the meter coordinate system\nwater_m = water_training_gdf.to_crs(\"EPSG:3857\")\nriver_m = rivers.to_crs(\"EPSG:3857\")\nwater_v_m = water_validation_gdf.to_crs(\"EPSG:3857\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "922ce49c-3164-4440-af26-30c71be46227",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "river_m.columns",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f6018bfc-50ac-459d-b80d-7f185ff37b4c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Join the points with the nearest river\ncombined_df = gpd.sjoin_nearest(\n    water_m,\n    river_m,\n    how=\"left\",\n    distance_col=\"dist_to_river_m\"\n)\n\ncombined_df.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5b89c61a-fda7-442e-a6dc-ff38166d7db3",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Join the points with the nearest river\ncombined_validation_df = gpd.sjoin_nearest(\n    water_v_m,\n    river_m,\n    how=\"left\",\n    distance_col=\"dist_to_river_m\"\n)\n\ncombined_validation_df.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a0faea2-7a7b-4419-aef9-6002ed86f878",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "combined_df[\"dist_to_river_m\"].describe(percentiles=[0.5,0.9,0.95,0.99])",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "944495bb-0fe8-4470-b7a6-aa61792d84f6",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "combined_validation_df[\"dist_to_river_m\"].describe(percentiles=[0.5,0.9,0.95,0.99])",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5b5381f1-cc77-482c-b7da-898d7ab5ef7c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Set the limit to 500m to avoid illogical join. \nmax_dist = 500  # 500m\ncombined_df.loc[combined_df[\"dist_to_river_m\"] > max_dist] = None\ncombined_validation_df.loc[combined_df[\"dist_to_river_m\"] > max_dist] = None",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6e529f3e-7022-4a5c-87bf-0535f1130c1e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "water_river = combined_df.drop(columns=\"geometry\") \nwater_river_validation = combined_validation_df.drop(columns=\"geometry\") \n\nwater_river.to_csv(\"water_with_river_training.csv\", index=False)\nwater_river_validation.to_csv(\"water_with_river_validation.csv\", index=False)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ed559b85-ca92-4e6d-9ccc-98829ae62ec2",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"\"\"\n    PUT file://water_with_river_training.csv\n    'snow://workspace/USER$.PUBLIC.\"EY-AI-and-Data-Challenge-Dev\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\n\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")\n\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b7188ae6-2df4-482c-88ee-88e51b3be2a6",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"\"\"\n    PUT file://water_with_river_validation.csv\n    'snow://workspace/USER$.PUBLIC.\"EY-AI-and-Data-Challenge-Dev\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\n\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")\n\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "23ef60c6-f82c-4719-a10a-dd409d98badc",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "water_river.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6dcea6d2-6c30-4066-a75b-8046159ae9ae",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Function for joining the data"
    },
    {
      "id": "686ca03f-006b-41b9-84ea-71ad7eb09068",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nimport geopandas as gpd\n\ndef to_points_gdf(\n    df: pd.DataFrame,\n    lon_col: str = \"Longitude\",\n    lat_col: str = \"Latitude\",\n    crs: str = \"EPSG:4326\",\n    drop_invalid: bool = True\n) -> gpd.GeoDataFrame:\n    \"\"\"\n    Convert a DataFrame with lon/lat columns into a GeoDataFrame of Point geometry.\n    Optionally drops rows with invalid/missing coordinates.\n    \"\"\"\n    df = df.copy()\n\n    # basic checks\n    if lon_col not in df.columns or lat_col not in df.columns:\n        raise ValueError(f\"Missing lon/lat columns: '{lon_col}', '{lat_col}'\")\n\n    # numeric coercion\n    df[lon_col] = pd.to_numeric(df[lon_col], errors=\"coerce\")\n    df[lat_col] = pd.to_numeric(df[lat_col], errors=\"coerce\")\n\n    # invalid coords\n    invalid = (\n        df[lon_col].isna() |\n        df[lat_col].isna() |\n        (df[lon_col] < -180) | (df[lon_col] > 180) |\n        (df[lat_col] < -90)  | (df[lat_col] > 90)\n    )\n\n    if drop_invalid and invalid.any():\n        df = df.loc[~invalid].copy()\n\n    gdf = gpd.GeoDataFrame(\n        df,\n        geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n        crs=crs\n    )\n    return gdf\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a53ef0ec-4514-48e2-8839-ef66d952be51",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "def join_nearest_layer(\n    points_gdf: gpd.GeoDataFrame,\n    layer_gdf: gpd.GeoDataFrame,\n    *,\n    layer_keep_cols: list[str] | None = None,\n    dist_col: str = \"dist_to_layer_m\",\n    max_dist_m: float | None = None,\n    metric_crs: str = \"EPSG:3857\",\n    how: str = \"left\"\n) -> gpd.GeoDataFrame:\n    \"\"\"\n    Spatially join points to the nearest feature in a layer (river lines, dam polygons, etc.)\n    Returns points with selected attributes from the layer + distance in meters.\n\n    - layer_keep_cols: columns to bring back from layer (excluding geometry; geometry auto handled)\n    - max_dist_m: if provided, any match beyond this distance will have joined columns set to NA\n    \"\"\"\n    # Decide which layer columns to keep\n    if layer_keep_cols is None:\n        # default: bring back all columns\n        cols = [c for c in layer_gdf.columns if c != \"geometry\"]\n    else:\n        missing = [c for c in layer_keep_cols if c not in layer_gdf.columns]\n        if missing:\n            raise ValueError(f\"layer_keep_cols not found in layer_gdf: {missing}\")\n        cols = layer_keep_cols\n\n    # Project both to metric CRS for distance correctness\n    pts_m = points_gdf.to_crs(metric_crs)\n    lyr_m = layer_gdf.to_crs(metric_crs)\n\n    # drop the \"index_right\" column to avoid the same name conflicts when joining.\n    pts_m = pts_m.drop(columns=[\"index_right\"], errors=\"ignore\")\n\n    # join\n    matched = gpd.sjoin_nearest(\n        pts_m,\n        lyr_m[cols + [\"geometry\"]],\n        how=how,\n        distance_col=dist_col\n    )\n\n    # apply max distance filter only to joined columns (keep original point columns)\n    if max_dist_m is not None:\n        too_far = matched[dist_col] > max_dist_m\n\n        # columns that came from layer (these are the ones we want to null out if too far)\n        joined_cols = cols\n\n        matched.loc[too_far, joined_cols] = pd.NA\n\n    return matched",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "516af806-f9b6-43fe-a6d7-2e6ce1f8fb76",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import geopandas as gpd\nimport pandas as pd\n\nrivers = gpd.read_file(\"Rivers_Data/Rivers.shp\")\ndams = gpd.read_file(\"Dams_Data/South_Africa_Dams.shp\") \n\ntest_df = pd.read_csv(\"submission_template.csv\") # the data we want to join",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d6c4c8d7-6acb-4e9b-b079-4ba8735703e0",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Transform the csv file to gdf\ntest_gdf = to_points_gdf(test_df, lon_col=\"Longitude\", lat_col=\"Latitude\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "544a2435-1726-4831-9317-88dff5aa3d60",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Define the columns we want to extract, default is set to be all columns\n# river_cols = []\n#dam_cols = []\n\ntest_with_river = join_nearest_layer(\n    test_gdf,\n    rivers,\n    # layer_keep_cols=river_cols,\n    dist_col=\"dist_to_river_m\",\n    max_dist_m=500,  # The max distance between the nearest river, for now we set to 500 meters.\n    metric_crs=\"EPSG:3857\"\n)\n\ntest_with_dam = join_nearest_layer(\n    test_with_river,\n    dams,\n    # layer_keep_cols=dam_cols,\n    dist_col=\"dist_to_dam_m\",\n    max_dist_m=5000,         # distance for dam to the point could be larger?\n    metric_crs=\"EPSG:3857\"\n)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "157e2364-49a3-427b-bf24-dce76b4b1b2e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "test_with_dam.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d870e39d-7ba6-4146-92ff-6dd9a76d0b55",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "",
      "outputs": [],
      "execution_count": null
    }
  ]
}